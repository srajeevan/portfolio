# Data Engineer

## Work Experience

**Big Data Analyst @ Insight Global - July 2022 - Present**
- Engineered and optimized data processing workflows using Pyspark and Python on the Databricks platform, achieving a 20% reduction in
runtime and a 15% decrease in resource utilization.
- Innovated in writing efficient code for data transformation and analysis, handling large volumes of data with Spark, and integrating Java and
Scala for additional functionality.
- Debugged and improved semi-structured data processing, transforming bronze tables into clean silver tables, and ensuring data quality and
consistency with advanced cleansing techniques.
- Embody a proactive approach to ad-hoc data analysis requests, utilizing Pyspark scripts to extract and analyze relevant data • for stakeholders.
- Applied data modeling and warehousing concepts to design robust database structures, focusing on scalability and robustness, and
incorporating best practices in data governance.
- Gained intermediate experience in configuring and scheduling data pipelines with Apache Airflow, Glue, and Redshift, and explored
additional distributed data processing frameworks like Apache Flink.
- Implemented a data validation system that caught and resolved 99% of data anomalies, thereby enhancing overall data integrity for critical
decision-making.
- Developed data transformation scripts for Looker and Domo, converting raw data into a structured format for insightful analytics.
- Created interactive dashboards using Looker, engineering views from silver tables and employing LookML to add custom logic tailored to
analytical needs.
- Collaborated with cross-functional teams to understand reporting requirements, translating them into visually appealing and user-friendly
dashboards while incorporating data visualization best practices.
- Worked closely with the data engineering team to deploy and maintain scalable and efficient data structures in a production environment,
leveraging containerization technologies like Docker and orchestration tools like Kubernetes.
- Optimized data storage and retrieval processes by leveraging AWS capabilities, handling data in various formats such as Parquet, JSON, and
Delta, and utilizing AWS components like S3 and Athena.

**BI Engineer @ Marchon Partners - March 2020 - July 2022**
- Collaborated with a cross-functional team in an agile environment to develop and design advanced data visualizations, including interactive
charts and comprehensive drill-down reports, using a blend of technologies such as Python, SQL, and Spark.
- Optimized data processing workflows in AWS EMR, achieving a 30% reduction in job execution time and enhancing data retrieval efficiency
for complex analytical queries.
- Designed and implemented robust dashboards and portals featuring critical KPIs and visuals for the Data Analytics platform, utilizing
Webfocus App Studio and custom reporting with FOCUS language.
- Engineered and launched a new ETL pipeline using Python, which led to a 20% increase in data processing speed and a 15% decrease in error
rates, significantly improving data quality and availability.
- Performed comprehensive unit testing on all written or modified programs, ensuring adherence to specifications and maintaining high
standards of software quality.
- Managed and executed scheduled reports through ReportCaster, ensuring timely delivery of daily, weekly, and monthly insights into the
Report Library.
- Utilized JIRA for efficient bug tracking, issue tracking, and project management, contributing to a streamlined development process.
- Leveraged AWS services, including EC2, S3, and Elastic Map Reduce (EMR), to build scalable and resilient data processing solutions.
- Developed a star database schema in Postgres and interfaced with the database using the psycopg2 Python PostgreSQL adapter, enhancing
the structure and accessibility of data storage.
- Conducted remediation, testing, and resolution of issues during each Webfocus/environment upgrade, demonstrating adaptability and a
commitment to continuous improvement.
- Created summary tables with embedded logic to optimize report execution, meeting analytical requirements and facilitating insightful data
analysis.
- Worked with AWS EMR cluster to execute Spark jobs, performing data transformations such as sort, join, aggregations, and filter to process
data from S3 into analytical tables.

**SQL DBA/BI Developer @ Amtex Systems Inc - March 2017 - February 2020**
- Engineered and optimized MS SQL server configurations, achieving a 20% improvement in performance through the refinement of stored
procedures and indexing, thereby enhancing data processing efficiency for large datasets.
- Developed and executed a robust Transactional Replication strategy to ensure seamless data movement to the failover SQL server,
contributing to system resilience and data integrity.
- Created and maintained database structures, including tables, stored procedures, views, and triggers, using SQL and integrated debugging
practices to ensure system stability.
- Optimized SQL Server Performance by redesigning query execution plans and indexing strategies, resulting in a 35% reduction in data
retrieval times and significantly faster report generation.
- Monitored production SQL databases and analyzed resource consumption using tools like SQL profiler and performance monitor, identifying
and resolving performance bottlenecks.
- Independently analyzed and troubleshoot SQL queries, refining execution plans and employing Python scripts for data manipulation tasks
when necessary.
- Built and monitored SQL server performance dashboards using the TICK stack framework and Grafana, providing real-time insights and
enabling proactive system management.
- Developed responsive Business Portals and BI dashboards with Webfocus Appstudio and InfoAssist+, improving Dashboard UI with HTML,
CSS, JavaScript, jQuery, and external JavaScript plugins.
- Supported and enhanced .NET web applications, utilizing C#, .Net Framework 4.5, MVC design patterns, and Entity Framework, while
providing candid feedback and implementing best practices.
- Implemented presentation layers in ASP.NET with MVC views, Partial Views, strongly-typed Views, Razor view engine, and HTML helpers,
ensuring a seamless user experience.

## Education
Computer Science <br/>
Lamar University • US, TX, Beaumont • 2016

## Skills

- Data Engineering : Analyze, Organize data, build data systems, data analysis, interpret trends and patterns, improving data quality, working
with nested data unstructured data.
- Database Management : SQL,PL SQL
- ETL Technologies : Airflow
- Data Modeling : Star Schema, Snowflake, ER Diagrams, UML Class Diagrams
- Distributed Computing : Spark, Pyspark in Databricks
- Cloud Computing : AWS services like S3, EC2, Athena, Redshift, Azure
- Programming Languages : Python, Pyspark, Javascript
- Containerization : Knowledge in Docker.
- Version Control : Git and GitHub
- Analytical Skills : Analytical and problem-solving skills, Looker, TIBCO Webfocus

## Projects

### AWS-Python_ETL_Pipeline_using_Airflow

This project demonstrates how to build and automate an ETL pipeline written in Python and schedule it using open source Apache Airflow orchestration tool on AWS EC2 instance.
#### AWS Services Used
- AWS EC2
- AWS S3
- Apache Airflow

#### Architecture Diagram

![Architecture_Diagram](https://github.com/srajeevan/AWS-Python_ETL_Pipeline_using_Airflow/assets/16627503/45e4047a-2d7b-4134-9b9f-d2ef31dba318)


### Youtube-Data-Analysis---AWS

This project securely manage, streamline, and perform analysis on the structured and semi-structured YouTube videos data based on the video categories and the trending metrics.
Used a Kaggle dataset which contains statistics (CSV files) on daily popular YouTube videos over the course of many months. There are up to 200 trending videos published every day for many locations. The data for each region is in its own file. The video title, channel title, publication time, tags, views, likes and dislikes, description, and comment count are among the items included in the data. A category_id field, which differs by area, is also included in the JSON file linked to the region.
Here is the link to the dataset
https://www.kaggle.com/datasets/datasnaek/youtube-new

#### AWS Services used in this project
- Amazon S3
- AWS Glue
- AWS Lambda
- AWS Athena
- AWS IAM
- Amazon QuickSight

#### Architecture Diagram

![Architecture Diagram](https://github.com/srajeevan/Youtube-Data-Analysis-AWS/blob/main/Assets/AWS%20Lambda_json_paquet.png)

